# -*- coding: utf-8 -*-
"""model_controlled_experiments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PjYECmhyXv5ESBwSPHswDXpkJdAaPNbA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import KFold, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import HistGradientBoostingRegressor


# =========================
# 0) Load & clean
# =========================
CSV_IN = "/content/faculty_scored_merged_with_rmp.csv"   # change to your path if needed
df = pd.read_csv(CSV_IN)

print("Raw rows:", len(df))

# Drop invalid target: avg_rating == 0
mask_y_zero = (df["avg_rating"] == 0)
df1 = df.loc[~mask_y_zero].copy()

# Drop missing keys used in experiments (we’ll require beauty_1to5 + school_name for experiments)
mask_missing = df1[["avg_rating", "beauty_1to5", "school_name"]].isna().any(axis=1)
df2 = df1.loc[~mask_missing].copy()

print("Dropped avg_rating==0:", int(mask_y_zero.sum()))
print("Dropped missing in (avg_rating, beauty_1to5, school_name):", int(mask_missing.sum()))
print("Usable rows:", len(df2))

y = df2["avg_rating"].astype(float)


# =========================
# 1) Controlled Experiments
#    Only change feature/representation; everything else fixed.
# =========================
EXPERIMENTS = [
    # E1: Beauty only
    {"exp": "E1 beauty_1to5 only", "num": ["beauty_1to5"], "cat": []},

    # E2: Beauty + school fixed effects (school_name one-hot)
    {"exp": "E2 + school_name FE", "num": ["beauty_1to5"], "cat": ["school_name"]},
]

# Optional controlled variants (only add if columns exist)
if "dept" in df2.columns:
    EXPERIMENTS.append({"exp": "E3 + school FE + dept", "num": ["beauty_1to5"], "cat": ["school_name", "dept"]})

if "pred_score_raw" in df2.columns:
    EXPERIMENTS.append({"exp": "E4 pred_score_raw only", "num": ["pred_score_raw"], "cat": []})
    EXPERIMENTS.append({"exp": "E5 pred_score_raw + school FE", "num": ["pred_score_raw"], "cat": ["school_name"]})


# =========================
# 2) Models & CV setup
# =========================
models = {
    "DummyMean": DummyRegressor(strategy="mean"),
    "LinearRegression": LinearRegression(),
    "Ridge(alpha=1.0)": Ridge(alpha=1.0, random_state=0),
    "HistGBR": HistGradientBoostingRegressor(random_state=0),
}

cv = KFold(n_splits=5, shuffle=True, random_state=0)
scoring = {
    "MAE": "neg_mean_absolute_error",
    "RMSE": "neg_root_mean_squared_error",
    "R2": "r2",
}

def make_preprocess(num_features, cat_features):
    numeric_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
    ])

    transformers = [("num", numeric_pipe, num_features)]

    if cat_features:
        categorical_pipe = Pipeline([
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("onehot", OneHotEncoder(handle_unknown="ignore")),
        ])
        transformers.append(("cat", categorical_pipe, cat_features))

    return ColumnTransformer(transformers, remainder="drop")


# =========================
# 3) Run controlled experiments (CV)
# =========================
rows = []
for exp_cfg in EXPERIMENTS:
    exp_name = exp_cfg["exp"]
    num_features = exp_cfg["num"]
    cat_features = exp_cfg["cat"]

    X = df2[num_features + cat_features].copy()
    preprocess = make_preprocess(num_features, cat_features)

    for model_name, model in models.items():
        pipe = Pipeline([("preprocess", preprocess), ("model", model)])
        out = cross_validate(pipe, X, y, cv=cv, scoring=scoring)

        mae = -out["test_MAE"]
        rmse = -out["test_RMSE"]
        r2 = out["test_R2"]

        rows.append({
            "experiment": exp_name,
            "model": model_name,
            "n": len(y),
            "MAE(mean)": mae.mean(),
            "MAE(std)": mae.std(ddof=1),
            "RMSE(mean)": rmse.mean(),
            "RMSE(std)": rmse.std(ddof=1),
            "R2(mean)": r2.mean(),
            "R2(std)": r2.std(ddof=1),
        })

res = pd.DataFrame(rows)
print("\n=== Controlled Experiments: 5-fold CV (mean ± std) ===")
print(res.sort_values(["experiment", "MAE(mean)", "model"]).to_string(index=False))

# Save table if you want
res.to_csv("controlled_experiments_cv_summary.csv", index=False)


# =========================
# 4) Visualization (comparative bar charts)
# =========================
def plot_metric(metric_mean, metric_std, title, ylabel, out_png):
    exp_order = list(dict.fromkeys(res["experiment"].tolist()))
    model_order = list(models.keys())

    plot_df = res.copy()
    plot_df["experiment"] = pd.Categorical(plot_df["experiment"], categories=exp_order, ordered=True)
    plot_df["model"] = pd.Categorical(plot_df["model"], categories=model_order, ordered=True)
    plot_df = plot_df.sort_values(["experiment", "model"])

    n_exp = len(exp_order)
    n_models = len(model_order)

    x = np.arange(n_exp)
    width = 0.18 if n_models >= 4 else 0.25
    offsets = (np.arange(n_models) - (n_models - 1) / 2) * width

    plt.figure(figsize=(max(10, 1.6*n_exp + 4), 5))
    for j, m in enumerate(model_order):
        sub = plot_df[plot_df["model"] == m]
        means = sub[metric_mean].to_numpy()
        stds  = sub[metric_std].to_numpy()

        plt.bar(x + offsets[j], means, width=width, label=str(m), yerr=stds, capsize=3)

    plt.xticks(x, exp_order, rotation=0)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend()
    plt.tight_layout()

    # Save then show (prevents blank images in many notebook setups)
    plt.savefig(out_png, dpi=200, bbox_inches="tight")
    plt.show()
    plt.close()

plot_metric("MAE(mean)", "MAE(std)",  "MAE by Experiment (5-fold CV)",  "MAE (lower is better)",  "cv_mae_by_experiment.png")
plot_metric("RMSE(mean)", "RMSE(std)", "RMSE by Experiment (5-fold CV)", "RMSE (lower is better)", "cv_rmse_by_experiment.png")
plot_metric("R2(mean)", "R2(std)",    "R² by Experiment (5-fold CV)",   "R² (higher is better)",  "cv_r2_by_experiment.png")

print("\nSaved:")
print(" - controlled_experiments_cv_summary.csv")
print(" - cv_mae_by_experiment.png")
print(" - cv_rmse_by_experiment.png")
print(" - cv_r2_by_experiment.png")